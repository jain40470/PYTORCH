{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('rnn_weights/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "with open('rnn_weights/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('rnn_weights/label_encoders.pkl', 'rb') as f:\n",
    "    labelencoders = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_cols = ['gender', 'age_group', 'region', 'product_category', \n",
    "                    'purchase_channel', 'platform', 'issue_resolved', 'complaint_registered']\n",
    "\n",
    "numerical_cols = ['customer_rating', 'response_time_hours']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_categorical(row):\n",
    "\n",
    "    for col in categorical_cols:\n",
    "\n",
    "        le = labelencoders[col]\n",
    "        \n",
    "        if row[col] in le.classes_:\n",
    "            row[col] = le.transform([row[col]])[0]\n",
    "        else:\n",
    "            row[col] = -1  # Unknown category\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_numerical(row, numerical_cols, scaler):\n",
    "\n",
    "    scaled = scaler.transform([[row[col] for col in numerical_cols]])\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "\n",
    "        row[col] = float(scaled[0][i])\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "\n",
    "  text = text.lower()\n",
    "  text = text.replace('?','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  \n",
    "  return text.split()\n",
    "\n",
    "def text_to_indices(text, vocab):\n",
    "\n",
    "  indexed_text = []\n",
    "\n",
    "  for token in tokenize(text):\n",
    "\n",
    "    if token in vocab:\n",
    "      indexed_text.append(vocab[token])\n",
    "    else:\n",
    "      indexed_text.append(vocab['<UNK>']) \n",
    "\n",
    "  return indexed_text\n",
    "\n",
    "def pad_sequence(seq, max_len, pad_value = 0):\n",
    "    \n",
    "    if len(seq) < max_len:\n",
    "        seq = seq + [pad_value] * (max_len - len(seq))\n",
    "    else:\n",
    "        seq = seq[:max_len]  # decrease\n",
    "    return seq\n",
    "\n",
    "\n",
    "def preprocess_review(text, vocab, max_len=6):\n",
    "\n",
    "    indexed = text_to_indices(text, vocab)\n",
    "    padded = pad_sequence(indexed, max_len,vocab['<PAD>'])\n",
    "    \n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size, text_emb_dim, rnn_hidden, feature_dim, num_classes , dropout_rate = 0.3):\n",
    "       \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, text_emb_dim, padding_idx=0)  \n",
    "        self.rnn = nn.RNN(text_emb_dim, rnn_hidden, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden + feature_dim , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_seq, feature):\n",
    "\n",
    "        x = self.embedding(text_seq)     \n",
    "    \n",
    "        hidden_combined , hidden_last = self.rnn(x)  # (all hidden combined , hidden for last step )\n",
    "\n",
    "        hidden_last = hidden_last.squeeze(0)\n",
    "\n",
    "        x = torch.cat([hidden_last, feature], dim=1)                  \n",
    "\n",
    "        out = self.fc(x)                     \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "feature_dim = 10\n",
    "num_classes = 3\n",
    "\n",
    "text_emb_dim = 16\n",
    "rnn_hidden = 64\n",
    "dropout_rate = 0.35541525567992005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNNModel(\n",
       "  (embedding): Embedding(56, 16, padding_idx=0)\n",
       "  (rnn): RNN(16, 64, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=74, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.35541525567992005, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SimpleRNNModel(vocab_size, text_emb_dim, rnn_hidden, feature_dim, num_classes , dropout_rate)\n",
    "model.load_state_dict(torch.load(\"rnn_weights/model_weights.pth\", map_location=\"cpu\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {'gender': 'string', \n",
    "'age_group': 'string', 'region': 'string', \n",
    "'product_category': 'string', \n",
    "'purchase_channel': 'string',\n",
    " 'platform': 'string', \n",
    " 'issue_resolved': 'string',\n",
    "  'complaint_registered': 'string',\n",
    "  'customer_rating': 0, \n",
    "  'response_time_hours': 0, \n",
    "  'review_text': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': -1, 'age_group': -1, 'region': -1, 'product_category': -1, 'purchase_channel': -1, 'platform': -1, 'issue_resolved': -1, 'complaint_registered': -1, 'customer_rating': -2.1375764685299474, 'response_time_hours': -1.7489223911054146, 'review_text': [1, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashjain/Desktop/Pytorch/Pyvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "row['review_text'] = preprocess_review(row['review_text'] , vocab )\n",
    "row = encode_categorical(row)\n",
    "row = scale_numerical(row, numerical_cols, scaler)\n",
    "\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = categorical_cols + numerical_cols\n",
    "feature_values = [row[col] for col in feature_cols]   \n",
    "\n",
    "seq = torch.tensor(row['review_text'],dtype=torch.long).unsqueeze(0)\n",
    "feature =  torch.tensor(feature_values, dtype=torch.float).unsqueeze(0) \n",
    "\n",
    "print(seq.shape)\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = {2: 'positive', 1: 'neutral', 0: 'negative'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    outputs = model(seq , feature)\n",
    "    _ , predicted = torch.max(outputs, 1)\n",
    "        \n",
    "    print(predicted.item())\n",
    "    print(sentiment[predicted.item()])\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
