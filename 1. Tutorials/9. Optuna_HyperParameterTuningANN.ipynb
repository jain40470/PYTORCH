{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "      <td>133</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>205</td>\n",
       "      <td>196</td>\n",
       "      <td>213</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>144</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>161</td>\n",
       "      <td>148</td>\n",
       "      <td>159</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>148</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>153</td>\n",
       "      <td>155</td>\n",
       "      <td>134</td>\n",
       "      <td>143</td>\n",
       "      <td>172</td>\n",
       "      <td>215</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>178</td>\n",
       "      <td>194</td>\n",
       "      <td>209</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>205</td>\n",
       "      <td>211</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>217</td>\n",
       "      <td>225</td>\n",
       "      <td>228</td>\n",
       "      <td>213</td>\n",
       "      <td>203</td>\n",
       "      <td>174</td>\n",
       "      <td>151</td>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0      9       0       0       0  ...       213       165         0         0\n",
       "1      7       0       0       0  ...         0         0         0         0\n",
       "2      0       0       0       0  ...         0         0         0         0\n",
       "3      8       0       0       0  ...         0         0         0         0\n",
       "4      8       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../2. Dataset/fmnist_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:].values / 255.0\n",
    "y = df.iloc[:,0].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , xtest , ytrain , ytest = train_test_split(x,y,test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tensor = torch.from_numpy(xtrain).float()\n",
    "xtest_tensor = torch.from_numpy(xtest).float()\n",
    "ytrain_tensor = torch.from_numpy(ytrain)\n",
    "ytest_tensor = torch.from_numpy(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        \n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(xtrain_tensor,ytrain_tensor)\n",
    "test_dataset = CustomDataset(xtest_tensor,ytest_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "\n",
    "  def __init__(self,input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "\n",
    "      layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "      layers.append(nn.ReLU())\n",
    "      layers.append(nn.Dropout(dropout_rate))\n",
    "      input_dim = neurons_per_layer\n",
    "    \n",
    "    layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "    self.network = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, features):\n",
    "\n",
    "    out = self.network(features)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if hasattr(torch,'mps') and torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"MPS is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(trial):\n",
    "\n",
    "  # Hyperparameter values from the search space\n",
    "  \n",
    "  num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
    "  dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "\n",
    "  epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
    "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "  batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "  \n",
    "  optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
    "  weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "  # Dataloader\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "  # model init\n",
    "  input_dim = 784\n",
    "  output_dim = 10\n",
    "\n",
    "  model = MyNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate)\n",
    "  model.to(device)\n",
    "\n",
    "  # optimizer selection\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "  if optimizer_name == 'Adam':\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "  elif optimizer_name == 'SGD':\n",
    "      optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "  else:\n",
    "      optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "  # Training loop\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "      # move data to gpu\n",
    "      batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "      # forward pass\n",
    "      outputs = model(batch_features)\n",
    "\n",
    "      # calculate loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "\n",
    "      # back pass\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "\n",
    "      # update grads\n",
    "      optimizer.step()\n",
    "\n",
    "\n",
    "  # Evaluation \n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  total = 0\n",
    "  correct = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "\n",
    "      # move data to gpu\n",
    "      batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "      outputs = model(batch_features)\n",
    "\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "      total = total + batch_labels.shape[0]\n",
    "\n",
    "      correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "    accuracy = correct/total\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashjain/Desktop/Pytorch/Pyvenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-12-03 18:10:15,336] A new study created in memory with name: no-name-7cfcac2b-a98d-46be-a361-f91442f0bde9\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashjain/Desktop/Pytorch/Pyvenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-03 18:11:55,207] Trial 0 finished with value: 0.62 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 8, 'dropout_rate': 0.2, 'epochs': 50, 'learning_rate': 0.003923593993445573, 'batch_size': 16, 'optimizer': 'SGD', 'weight_decay': 0.00034035167994113955}. Best is trial 0 with value: 0.62.\n",
      "[I 2025-12-03 18:12:31,836] Trial 1 finished with value: 0.43833333333333335 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 24, 'dropout_rate': 0.5, 'epochs': 30, 'learning_rate': 0.018089929301193675, 'batch_size': 16, 'optimizer': 'SGD', 'weight_decay': 0.0003716149924262154}. Best is trial 0 with value: 0.62.\n",
      "[I 2025-12-03 18:13:20,824] Trial 2 finished with value: 0.6658333333333334 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 32, 'dropout_rate': 0.30000000000000004, 'epochs': 30, 'learning_rate': 3.198128703239323e-05, 'batch_size': 16, 'optimizer': 'RMSprop', 'weight_decay': 0.00015259318561752249}. Best is trial 2 with value: 0.6658333333333334.\n",
      "[I 2025-12-03 18:13:23,429] Trial 3 finished with value: 0.7333333333333333 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 80, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 2.067591788771181e-05, 'batch_size': 64, 'optimizer': 'RMSprop', 'weight_decay': 2.2377533909393123e-05}. Best is trial 3 with value: 0.7333333333333333.\n",
      "[I 2025-12-03 18:13:31,269] Trial 4 finished with value: 0.8391666666666666 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 128, 'dropout_rate': 0.1, 'epochs': 30, 'learning_rate': 0.0005956055296341781, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 0.0002561742542064322}. Best is trial 4 with value: 0.8391666666666666.\n",
      "[I 2025-12-03 18:13:35,400] Trial 5 finished with value: 0.6416666666666667 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 48, 'dropout_rate': 0.5, 'epochs': 20, 'learning_rate': 4.541144366226724e-05, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 0.00045385432690789014}. Best is trial 4 with value: 0.8391666666666666.\n",
      "[I 2025-12-03 18:13:55,787] Trial 6 finished with value: 0.8116666666666666 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 96, 'dropout_rate': 0.4, 'epochs': 30, 'learning_rate': 0.0338208544860999, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 8.68701993066155e-05}. Best is trial 4 with value: 0.8391666666666666.\n",
      "[I 2025-12-03 18:14:00,161] Trial 7 finished with value: 0.8191666666666667 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 72, 'dropout_rate': 0.1, 'epochs': 20, 'learning_rate': 0.0018090545634450715, 'batch_size': 64, 'optimizer': 'Adam', 'weight_decay': 0.00029765406795752465}. Best is trial 4 with value: 0.8391666666666666.\n",
      "[I 2025-12-03 18:14:09,084] Trial 8 finished with value: 0.8333333333333334 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 56, 'dropout_rate': 0.2, 'epochs': 50, 'learning_rate': 0.0003448369101796975, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 0.00010733645667942492}. Best is trial 4 with value: 0.8391666666666666.\n",
      "[I 2025-12-03 18:14:14,625] Trial 9 finished with value: 0.8166666666666667 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 32, 'dropout_rate': 0.2, 'epochs': 20, 'learning_rate': 0.0004513385909055468, 'batch_size': 64, 'optimizer': 'RMSprop', 'weight_decay': 0.00018116120202961333}. Best is trial 4 with value: 0.8391666666666666.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
