{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../2. Dataset/100_Unique_QA_Dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "  text = text.lower()\n",
    "  text = text.replace('?','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  \n",
    "  return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'the', 'capital', 'of', 'france']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<UNK>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "  \n",
    "  tokenized_question = tokenize(row['question'])\n",
    "  \n",
    "  tokenized_answer = tokenize(row['answer'])\n",
    "\n",
    "  merged_tokens = tokenized_question + tokenized_answer\n",
    "\n",
    "  for token in merged_tokens:\n",
    "\n",
    "    if token not in vocab:\n",
    "      \n",
    "      vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab, axis=1) # for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab):\n",
    "\n",
    "  indexed_text = []\n",
    "\n",
    "  for token in tokenize(text):\n",
    "\n",
    "    if token in vocab:\n",
    "      indexed_text.append(vocab[token])\n",
    "    else:\n",
    "      indexed_text.append(vocab['<UNK>'])\n",
    "\n",
    "  return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "\n",
    "  def __init__(self, df, vocab):\n",
    "\n",
    "    self.df = df\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def __len__(self):\n",
    "    \n",
    "    return self.df.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
    "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
    "\n",
    "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "q , a = dataset[0]\n",
    "print(q.shape , a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)  \n",
    "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "    #  nn.RNN(50, 64, batch_first=True, nonlinearity='relu') ,\n",
    "    #  you can do this to change activation function , default is tanh\n",
    "    self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "  def forward(self, question):\n",
    "\n",
    "    embedded_question = self.embedding(question)  # this is flexible like you can pass in batch , seq or even a singel word\n",
    "    hidden, final = self.rnn(embedded_question)\n",
    "    output = self.fc(final.squeeze(0))  \n",
    "\n",
    "    # ex : (2,3) => (2,3,50) => hidden : (2,3,64) , final : (1,2,64) => final then squezze : (2,vocab size)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a: torch.Size([1, 6])\n",
      "shape of b: torch.Size([1, 6, 50])\n",
      "shape of c: torch.Size([1, 6, 64])\n",
      "shape of d: torch.Size([1, 1, 64])\n",
      "shape of e: torch.Size([1, 324])\n"
     ]
    }
   ],
   "source": [
    "x = nn.Embedding(324, embedding_dim=50)\n",
    "y = nn.RNN(50, 64, batch_first=True)\n",
    "z = nn.Linear(64, 324)\n",
    "\n",
    "a = dataset[0][0].reshape(1,6)\n",
    "print(\"shape of a:\", a.shape)\n",
    "b = x(a)\n",
    "print(\"shape of b:\", b.shape)\n",
    "c, d = y(b)\n",
    "print(\"shape of c:\", c.shape)\n",
    "print(\"shape of d:\", d.shape)\n",
    "\n",
    "e = z(d.squeeze(0))\n",
    "\n",
    "print(\"shape of e:\", e.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write about c , d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 528.090919\n",
      "Epoch: 2, Loss: 458.714390\n",
      "Epoch: 3, Loss: 378.145655\n",
      "Epoch: 4, Loss: 319.229693\n",
      "Epoch: 5, Loss: 268.699638\n",
      "Epoch: 6, Loss: 219.591051\n",
      "Epoch: 7, Loss: 175.431788\n",
      "Epoch: 8, Loss: 136.682385\n",
      "Epoch: 9, Loss: 105.355241\n",
      "Epoch: 10, Loss: 79.890064\n",
      "Epoch: 11, Loss: 61.585481\n",
      "Epoch: 12, Loss: 48.281191\n",
      "Epoch: 13, Loss: 38.078587\n",
      "Epoch: 14, Loss: 31.051787\n",
      "Epoch: 15, Loss: 25.467780\n",
      "Epoch: 16, Loss: 21.294527\n",
      "Epoch: 17, Loss: 17.820949\n",
      "Epoch: 18, Loss: 15.242909\n",
      "Epoch: 19, Loss: 13.066979\n",
      "Epoch: 20, Loss: 11.353748\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "  total_loss = 0\n",
    "\n",
    "  for question, answer in dataloader:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(question)\n",
    "\n",
    "    # loss -> output shape (1,324) - (1)\n",
    "    # inside CrossEntropyLoss => Apply Softmax → convert logits → probabilities\n",
    "\n",
    "    loss = criterion(output, answer[0])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "\n",
    "  numerical_question = text_to_indices(question, vocab)\n",
    "\n",
    "  print(\"numerical_question\" ,len(numerical_question) )\n",
    "\n",
    "  question_tensor = torch.tensor(numerical_question).unsqueeze(0) # adding  a batch dim\n",
    "\n",
    "  print(\"question_tensor\" ,question_tensor.shape )\n",
    "\n",
    "  output = model(question_tensor)\n",
    "\n",
    "  print(\"output\" , output.shape)\n",
    "\n",
    "  probs = torch.nn.functional.softmax(output, dim=1)  # along row\n",
    "\n",
    "  print(\"probs\" , probs.shape)\n",
    "\n",
    "  value, index = torch.max(probs, dim=1)  \n",
    "\n",
    "  if value < threshold:\n",
    "    print(\"I don't know\")\n",
    "\n",
    "  print(list(vocab.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_question 9\n",
      "question_tensor torch.Size([1, 9])\n",
      "output torch.Size([1, 324])\n",
      "probs torch.Size([1, 324])\n",
      "jupiter\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"What is the largest planet in our solar system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
